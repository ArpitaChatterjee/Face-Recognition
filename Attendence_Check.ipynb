{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attendence_Check.ipynb",
      "provenance": [],
      "mount_file_id": "11hYQ1PTM3GLNwpzLJl84fSiQqts9FyHM",
      "authorship_tag": "ABX9TyPDuQqo21dEF+W2hhjeA2je",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArpitaChatterjee/Face-Recognition/blob/main/Attendence_Check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vnzc-o_MLqK",
        "outputId": "693f9e15-3e13-44e4-f929-fd307cde02ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip  install dlib==19.18.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dlib==19.18.0 in /usr/local/lib/python3.6/dist-packages (19.18.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi9c0c_2J5fx",
        "outputId": "62c506c9-7f50-4076-a655-6e9f81622d31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install face_recognition\n",
        "import dlib\n",
        "import face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.5)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=d204b52faa74e5a5f503c23901f2866fe89a3e9e556cb86468c8eb9cae4ce2ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wQd7muAL8DF",
        "outputId": "5ed972d6-1c4d-4f76-8a0b-3cb496572bb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install opencv-python\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-0TDFPDM3Q2",
        "outputId": "35981922-9c60-428e-edcf-b421ffbcfb74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/Face Recognition/ImagesAttendance'\n",
        "images=[]\n",
        "classNames=[]\n",
        "mylist= os.listdir(path)\n",
        "print(mylist)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bill Gates.jpg', 'Jack Ma.jpg', 'Elon Musk.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9Lhe7HIO1g-",
        "outputId": "57495cfb-b8ba-4f3a-fc85-ddcd1e9be6f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for cl in mylist:\n",
        "  curImg = cv2.imread(f'{path}/{cl}')\n",
        "  images.append(curImg)\n",
        "  classNames.append(os.path.splitext(cl)[0])\n",
        "print(classNames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Bill Gates', 'Jack Ma', 'Elon Musk']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5j84NrUPkDB",
        "outputId": "7dbf3ac0-3e53-4e71-c6c7-60ae3d0b586c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def findEncodings(images):\n",
        "  encodeList =[]\n",
        "  for img in images:\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    encode = face_recognition.face_encodings(img)[0]\n",
        "    encodeList.append(encode)\n",
        "  return encodeList\n",
        "\n",
        "encodelistknown = findEncodings(images)\n",
        "print(len(encodelistknown))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRsP5BsIQ9Cy",
        "outputId": "edf352dc-8d04-4d3b-b96c-d6a1c8be159c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('encoding Complete')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoding Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6rC5YxpYe1J"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(cap, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return cap\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrVLbQbJYe0U",
        "outputId": "e39842cc-7f0d-42d5-d5e2-e5508a8d1fa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "expected str, bytes or os.PathLike object, not cv2.VideoCapture\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmiFHPgTRGQb"
      },
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "  sucess, img = cap.read()\n",
        "  imgS = cv2.resize(img, (0,0), None, 0.25, 0.25)\n",
        "  imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RBG)\n",
        "\n",
        "  facesCurFrame = face_recognition.face_locations(imgS)\n",
        "  encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
        "\n",
        "  for encodeFace, faceloc in zip(encodesCurFrame, facesCurFrame):\n",
        "    matches = face_recognition.compare_faces(encodelistknown, encodeFace)\n",
        "    faceDis = face_recognition.face_distance(encodelistknown, encodeFace)\n",
        "    print(faceDis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBH_XDOckfpO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vNYgx0eQKkc"
      },
      "source": [
        "##ecode for original face\n",
        "faceLoc = face_recognition.face_locations(imgElon)[0]\n",
        "encodeElon = face_recognition.face_encodings(imgElon)[0]\n",
        "cv2.rectangle(imgElon,(faceLoc[3], faceLoc[0]), (faceLoc[1],faceLoc[2]),(255,0, 255),2)\n",
        "print(faceLoc)\n",
        "\n",
        "\n",
        "#for the test img loc\n",
        "faceLocTest = face_recognition.face_locations(imgTest)[0]\n",
        "encodeTest= face_recognition.face_encodings(imgTest)[0]\n",
        "cv2.rectangle(imgTest,(faceLocTest[3], faceLocTest[0]), (faceLocTest[1],faceLocTest[2]),(255,0, 255),2)\n",
        "print(faceLocTest)\n",
        "\n",
        "results = face_recognition.compare_faces([encodeElon], encodeTest)\n",
        "faceDis =face_recognition.face_distance([encodeElon], encodeTest)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}